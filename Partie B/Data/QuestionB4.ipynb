{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/dominicprenovost/Programmation/TP2-PF-management/48_Industry_Portfolios.CSV'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_monthly \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/dominicprenovost/Programmation/TP2-PF-management/48_Industry_Portfolios.CSV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_monthly \u001b[38;5;241m=\u001b[39m df_monthly\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      4\u001b[0m df_48ind \u001b[38;5;241m=\u001b[39m df_monthly\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m1171\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dominicprenovost/Programmation/TP2-PF-management/48_Industry_Portfolios.CSV'"
     ]
    }
   ],
   "source": [
    "df_monthly = pd.read_csv('/Users/dominicprenovost/Programmation/TP2-PF-management/48_Industry_Portfolios.CSV', header=6)\n",
    "df_monthly = df_monthly.rename(columns={'Unnamed: 0': 'Date'})\n",
    "\n",
    "df_48ind = df_monthly.iloc[:1171].copy()\n",
    "df_48ind['Date'] = pd.to_datetime(df_48ind['Date'], format='%Y%m')\n",
    "df_48ind.set_index('Date', inplace=True)\n",
    "df_48ind = df_48ind.apply(pd.to_numeric, errors='coerce')\n",
    "df_48ind.replace(-99.99, np.nan, inplace = True)\n",
    "df_48ind.replace(-999, np.nan, inplace = True)\n",
    "df_48ind.dropna(inplace = True)\n",
    "\n",
    "df_numfirm = df_monthly.iloc[2564-20:3735-20].copy()\n",
    "df_numfirm['Date'] = pd.to_datetime(df_numfirm['Date'], format='%Y%m')\n",
    "df_numfirm.set_index('Date', inplace=True)\n",
    "df_numfirm = df_numfirm.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df_avgsize = df_monthly.iloc[3739-22:4910-22].copy()\n",
    "df_avgsize['Date'] = pd.to_datetime(df_avgsize['Date'], format='%Y%m')\n",
    "df_avgsize.set_index('Date', inplace=True)\n",
    "df_avgsize = df_avgsize.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "df_MC = df_numfirm.multiply(df_avgsize, axis=0)\n",
    "df_MC = df_MC.loc[df_48ind.index]\n",
    "\n",
    "\n",
    "df_BtoM = df_monthly.iloc[4890:4988].copy()\n",
    "df_BtoM = df_BtoM.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df_BtoM = df_BtoM.loc[df_BtoM.index.repeat(12)].reset_index(drop=True)\n",
    "\n",
    "df_BtoM['Date'] = pd.to_datetime(df_BtoM['Date'], format='%Y')\n",
    "\n",
    "df_BtoM = df_BtoM.drop('Date', axis=1)\n",
    "\n",
    "df_BtoM.replace(-99.99, np.nan, inplace = True)\n",
    "df_BtoM.replace(-999, np.nan, inplace = True)\n",
    "df_BtoM.dropna(inplace = True)\n",
    "\n",
    "df_BtoM = pd.DataFrame(data = df_BtoM.iloc[5:].values, index = df_48ind.index, columns = df_48ind.columns)\n",
    "\n",
    "\n",
    "df_mom = df_48ind.rolling(window=12).mean()\n",
    "\n",
    "df_mom.replace(-99.99, np.nan, inplace = True)\n",
    "df_mom.replace(-999, np.nan, inplace = True)\n",
    "df_mom.dropna(inplace = True)\n",
    "\n",
    "df_48ind = df_48ind.loc[df_mom.index]\n",
    "df_MC = df_MC.loc[df_mom.index]\n",
    "df_BtoM = df_BtoM.loc[df_mom.index]\n",
    "\n",
    "df_ret_shift = df_48ind.shift(-1)\n",
    "\n",
    "############ 5 factors    ##############\n",
    "\n",
    "df_FF_5factors = pd.read_csv('/Users/dominicprenovost/Programmation/TP2-PF-management/F-F_Research_Data_5_Factors_2x3.CSV', header=2)\n",
    "df_FF_5factors = df_FF_5factors.rename(columns={'Unnamed: 0': 'Date'})\n",
    "df_FF_5 = df_FF_5factors.iloc[:727].copy()\n",
    "df_FF_5['Date'] = pd.to_datetime(df_FF_5['Date'], format='%Y%m')\n",
    "df_FF_5.set_index('Date', inplace=True)\n",
    "df_FF_5 = df_FF_5.apply(pd.to_numeric, errors='coerce')\n",
    "df_FF_5 = df_FF_5.loc[df_mom.index]\n",
    "\n",
    "df_daily = pd.read_csv('/Users/dominicprenovost/Programmation/TP2-PF-management/48_Industry_Portfolios_Daily.csv', header=5)\n",
    "df_daily = df_daily.rename(columns={'Unnamed: 0': 'Date'})\n",
    "\n",
    "df_daily_ret = df_daily.iloc[:25670].copy()\n",
    "df_daily_ret['Date'] = pd.to_datetime(df_daily_ret['Date'], format='%Y%m%d')\n",
    "df_daily_ret.set_index('Date', inplace=True)\n",
    "df_daily_ret = df_daily_ret.apply(pd.to_numeric, errors='coerce')\n",
    "df_daily_ret.replace(-99.99, np.nan, inplace = True)\n",
    "df_daily_ret.replace(-999, np.nan, inplace = True)\n",
    "df_daily_ret.dropna(inplace = True)\n",
    "\n",
    "df_daily_ret_reshaped = df_daily_ret.iloc[231:].copy()\n",
    "\n",
    "########## 3 factors ########## \n",
    "\n",
    "df_FF_3 = pd.read_csv('/Users/dominicprenovost/Programmation/TP2-PF-management/F-F_Research_Data_Factors_daily.CSV', header=3)\n",
    "df_FF_3 = df_FF_3.rename(columns={'Unnamed: 0': 'Date'})\n",
    "df_FF_daily = df_FF_3.iloc[:25670].copy()\n",
    "df_FF_daily['Date'] = pd.to_datetime(df_FF_daily['Date'], format='%Y%m%d')\n",
    "df_FF_daily.set_index('Date', inplace=True)\n",
    "df_FF_daily = df_FF_daily.apply(pd.to_numeric, errors='coerce')\n",
    "df_FF_daily.replace(-99.99, np.nan, inplace = True)\n",
    "df_FF_daily.replace(-999, np.nan, inplace = True)\n",
    "df_FF_daily.dropna(inplace = True)\n",
    "df_FF_daily = df_FF_daily.loc[df_daily_ret.index]\n",
    "\n",
    "rf = df_FF_daily['RF'].mean()\n",
    "\n",
    "######################################## 1.1 ########################################\n",
    "\n",
    "def calculate_betas(start_date, end_date, df_daily_ret_reshaped, df_FF_daily):\n",
    "    # Sélectionner les données pour la plage de dates spécifiée\n",
    "    df_daily_ret_selected = df_daily_ret_reshaped.loc[start_date:end_date]\n",
    "    df_FF_daily_selected = df_FF_daily.loc[start_date:end_date]\n",
    "\n",
    "    # Maintenant, vous pouvez utiliser df_daily_ret_selected et df_FF_daily_selected pour votre régression\n",
    "    Rft = df_FF_daily_selected['RF']\n",
    "    Rm_t = df_FF_daily_selected['Mkt-RF']\n",
    "\n",
    "    betas = []  # Create an empty list to store the betas\n",
    "\n",
    "    for column in df_daily_ret_selected.columns:\n",
    "        Ri_t = df_daily_ret_selected[column]\n",
    "\n",
    "        Y = Ri_t - Rft\n",
    "        X = Rm_t\n",
    "\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "\n",
    "        betas.append(results.params[1])  # Add the betas to the list\n",
    "\n",
    "    # Convert the list of betas to a numpy array\n",
    "    betas = np.array(betas)\n",
    "\n",
    "    return betas\n",
    "\n",
    "\n",
    "# Get the first and last date in the data\n",
    "first_date = df_daily_ret_reshaped.index.min()\n",
    "last_date = df_daily_ret_reshaped.index.max()\n",
    "\n",
    "# Create a date range for each month in the data\n",
    "date_range = pd.date_range(start=first_date, end=last_date, freq='M')\n",
    "\n",
    "# Calculate the betas for each month\n",
    "monthly_betas = {}\n",
    "for date in date_range:\n",
    "    start_date = date - pd.DateOffset(months=12)\n",
    "    end_date = date\n",
    "    betas = calculate_betas(start_date, end_date, df_daily_ret, df_FF_daily)\n",
    "    monthly_betas[date] = betas\n",
    "    \n",
    "    # Convert the dictionary to a DataFrame\n",
    "df_monthly_betas = pd.DataFrame(monthly_betas.items(), columns=['Date', 'Betas'])\n",
    "\n",
    "# Convert the Betas column from numpy arrays to lists\n",
    "df_monthly_betas['Betas'] = df_monthly_betas['Betas'].apply(list)\n",
    "\n",
    "# Set the Date column as the index\n",
    "df_monthly_betas.set_index('Date', inplace=True)\n",
    "\n",
    "# Convert each item in the 'Betas' list to a separate column\n",
    "df_monthly_betas = df_monthly_betas['Betas'].apply(pd.Series)\n",
    "\n",
    "# Set the index of df_monthly_betas to match df_48ind\n",
    "df_monthly_betas.index = df_48ind.index\n",
    "\n",
    "# Set the column names of df_monthly_betas to match df_48ind\n",
    "df_monthly_betas.columns = df_48ind.columns\n",
    "\n",
    "def calculate_idiosyncratic_volatility(start_date, end_date, df_daily_ret_reshaped, df_FF_daily):\n",
    "    # Sélectionner les données pour la plage de dates spécifiée\n",
    "    df_daily_ret_selected = df_daily_ret_reshaped.loc[start_date:end_date]\n",
    "    df_FF_daily_selected = df_FF_daily.loc[start_date:end_date]\n",
    "\n",
    "    # Maintenant, vous pouvez utiliser df_daily_ret_selected et df_FF_daily_selected pour votre régression\n",
    "    Rft = df_FF_daily_selected['RF']\n",
    "    Rm_t = df_FF_daily_selected['Mkt-RF']\n",
    "    SMB = df_FF_daily_selected['SMB']\n",
    "    HML = df_FF_daily_selected['HML']\n",
    "\n",
    "    volatilities = []  # Create an empty list to store the volatilities\n",
    "\n",
    "    for column in df_daily_ret_selected.columns:\n",
    "        Ri_t = df_daily_ret_selected[column]\n",
    "\n",
    "        Y = Ri_t - Rft\n",
    "        X = pd.concat([Rm_t, SMB, HML], axis=1)\n",
    "\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "\n",
    "        residuals = results.resid\n",
    "        volatility = np.std(residuals)\n",
    "\n",
    "        volatilities.append(volatility)  # Add the volatility to the list\n",
    "\n",
    "    # Convert the list of volatilities to a numpy array\n",
    "    volatilities = np.array(volatilities)\n",
    "\n",
    "    return volatilities\n",
    "\n",
    "\n",
    "# Get the first and last date in the data\n",
    "first_date = df_daily_ret_reshaped.index.min()\n",
    "last_date = df_daily_ret_reshaped.index.max()\n",
    "\n",
    "# Create a date range for each month in the data\n",
    "date_range = pd.date_range(start=first_date, end=last_date, freq='M')\n",
    "\n",
    "# Calculate the volatilities for each month\n",
    "monthly_volatilities = {}\n",
    "for date in date_range:\n",
    "    start_date = date  - pd.DateOffset(months=1) + pd.DateOffset(days=1)\n",
    "    end_date = date\n",
    "    volatilities = calculate_idiosyncratic_volatility(start_date, end_date, df_daily_ret, df_FF_daily)\n",
    "    monthly_volatilities[date] = volatilities\n",
    "    \n",
    "        # Convert the dictionary to a DataFrame\n",
    "df_monthly_vol = pd.DataFrame(monthly_volatilities.items(), columns=['Date', 'Betas'])\n",
    "\n",
    "# Convert the Betas column from numpy arrays to lists\n",
    "df_monthly_vol['Betas'] = df_monthly_vol['Betas'].apply(list)\n",
    "\n",
    "# Set the Date column as the index\n",
    "df_monthly_vol.set_index('Date', inplace=True)\n",
    "\n",
    "# Convert each item in the 'Betas' list to a separate column\n",
    "df_monthly_vol = df_monthly_vol['Betas'].apply(pd.Series)\n",
    "\n",
    "# Set the index of df_monthly_vol to match df_48ind\n",
    "df_monthly_vol.index = df_48ind.index\n",
    "\n",
    "# Set the column names of df_monthly_vol to match df_48ind\n",
    "df_monthly_vol.columns = df_48ind.columns\n",
    "\n",
    "\n",
    "def select_extreme_values(row, num_values=5):\n",
    "    sorted_row = row.sort_values(ascending=False)\n",
    "    top_values = sorted_row.head(num_values)\n",
    "    bottom_values = sorted_row.tail(num_values)\n",
    "    return top_values, bottom_values\n",
    "\n",
    "\n",
    "def get_returns(caracteristic, df_ret_shift, num_positions, weight_type='ew'):\n",
    "    \n",
    "    top_bottom_values = caracteristic.apply(select_extreme_values, axis=1)\n",
    "    \n",
    "    returns = []\n",
    "    total_returns = []\n",
    "    \n",
    "    for date, values in top_bottom_values.items():\n",
    "        top_indices, bottom_indices = values[0].index, values[1].index\n",
    "        \n",
    "        if weight_type == 'ew':\n",
    "            weight = 1.0 / num_positions\n",
    "            top_returns = df_ret_shift.loc[date, top_indices] * weight\n",
    "            bottom_returns = df_ret_shift.loc[date, bottom_indices] * weight * -1  # short positions have negative weight\n",
    "        elif weight_type == 'vw':\n",
    "            top_values = df_ret_shift.loc[date, top_indices]\n",
    "            bottom_values = df_ret_shift.loc[date, bottom_indices]\n",
    "            top_weights = top_values.abs() / top_values.abs().sum()\n",
    "            bottom_weights = bottom_values.abs() / bottom_values.abs().sum()\n",
    "            top_returns = top_values * top_weights\n",
    "            bottom_returns = bottom_values * bottom_weights * -1  # short positions have negative weight\n",
    "        else:\n",
    "            raise ValueError(\"weight_type must be either 'ew' or 'vw'\")\n",
    "        \n",
    "        returns.append((top_returns.sum(), bottom_returns.sum()))\n",
    "    \n",
    "    total_returns = [sum(x) for x in returns]\n",
    "\n",
    "    return total_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importClean_Ind(csv_file_path, desired_returns):\n",
    "    \"\"\"\n",
    "    Cette fonction importe des données à partir d'un fichier CSV spécifié, effectue un nettoyage de données,\n",
    "    et retourne un DataFrame contenant des données filtrées.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path(str): Chemin vers le fichier CSV avec les données brutes.\n",
    "\n",
    "    Return:\n",
    "        DataFrame: DataFrame contenant les données historiques filtrées pour les 10 industries, \n",
    "        pour les 48 industries et certains facteurs de Fama-French.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Importation\n",
    "    with open(csv_file_path, 'r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        \n",
    "        # Sauter les 10 premières lignes\n",
    "        for _ in range(10):\n",
    "            next(reader)\n",
    "\n",
    "        # Lire le reste du fichier CSV dans un DataFrame\n",
    "        df = pd.DataFrame(reader)\n",
    "        df.columns = df.iloc[1]\n",
    "        df = df.drop(df.index[1])\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    # Nettoyage\n",
    "    df = df.rename(columns={df.columns[0]: 'Date'})\n",
    "    first_row = df[df.iloc[:, 0].str.strip() == desired_returns].index\n",
    "    \n",
    "    # Si 'desired_returns' est 'Number of Firms in Portfolios' ou 'Average Firm Size', \n",
    "    # alors sauter une ligne supplémentaire pour accéder aux données dans le bon format\n",
    "    if desired_returns in ['Number of Firms in Portfolios', 'Average Firm Size', 'Sum of BE / Sum of ME']:\n",
    "        df_AEWR_monthly = df.iloc[first_row.values[0] + 2:].reset_index(drop=True)\n",
    "    else:\n",
    "        df_AEWR_monthly = df.iloc[first_row.values[0] + 1:].reset_index(drop=True)\n",
    "        \n",
    "    last_row = (df_AEWR_monthly['Date'].str.len() != 6).idxmax()\n",
    "    df_AEWR_monthly = df_AEWR_monthly.iloc[:last_row]\n",
    "    \n",
    "    # Adapter le format de la date en fonction de 'desired_returns'\n",
    "    # Condition spécifique pour le facteur BtoM (Book-to-Market)\n",
    "    if desired_returns in ['Sum of BE / Sum of ME']:  \n",
    "        df_AEWR_monthly['Date'] = df_AEWR_monthly['Date'].str.strip()\n",
    "        df_AEWR_monthly['Date'] = pd.to_datetime(df_AEWR_monthly['Date'], format='%Y')\n",
    "    else:\n",
    "        df_AEWR_monthly['Date'] = pd.to_datetime(df_AEWR_monthly['Date'], format='%Y%m')\n",
    "    \n",
    "    df_AEWR_monthly.iloc[:, 1:] = df_AEWR_monthly.iloc[:, 1:].astype(float)\n",
    "\n",
    "    # Vérifier si le nom du fichier contient '48_Industry_Portfolios.CSV',\n",
    "    # pour appliquer un nettoyage supplémentaire pour les NaN values\n",
    "    if '48_Industry_Portfolios.CSV' in os.path.basename(csv_file_path):\n",
    "        df_AEWR_monthly.replace(-99.99, np.nan, inplace=True)\n",
    "        df_AEWR_monthly.replace(-999, np.nan, inplace=True)\n",
    "        df_AEWR_monthly.dropna(inplace=True)\n",
    "        \n",
    "    # Retourner le DataFrame et fixer la 'Date' comme index  \n",
    "    df = df_AEWR_monthly.set_index('Date', drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importClean_rf(csv_file_path):\n",
    "    \"\"\"\n",
    "    Cette fonction importe des données à partir du fichier CSV des 3 facteurs Fama-French, puis effectue un nettoyage de données\n",
    "    et retourne un DataFrame contenant des données filtrées spécifiquement pour les taux sans risque dans la colonne 'RF'.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): Chemin vers le fichier CSV avec les données brutes.\n",
    "\n",
    "    Return:\n",
    "        DataFrame: DataFrame contenant les données nettoyées pour les taux sans risque.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Importation des données en sautant les 3 premières lignes\n",
    "    df = pd.read_csv(csv_file_path, skiprows=3)  \n",
    "\n",
    "    # Renommage des colonnes pour faciliter la manipulation\n",
    "    df.columns = ['Date', 'Mkt-RF', 'SMB', 'HML', 'RF']\n",
    "\n",
    "    # Suppression des lignes dont la date ne correspond pas au format '%Y%m'\n",
    "    df = df[df['Date'].str.match(r'^\\d{6}$', na=False)]\n",
    "\n",
    "    # Conversion de 'Date' en datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y%m')\n",
    "\n",
    "    # Conversion de 'RF' en float\n",
    "    df['RF'] = df['RF'].astype(float)\n",
    "    \n",
    "    # Filtrage des colonnes \n",
    "    df = df[['Date', 'RF']] \n",
    "    \n",
    "    # Mise en index de la colonne 'Date'\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_prepare_daily_data(csv_file_path):\n",
    "    \"\"\"\n",
    "    Importe et prépare les données quotidiennes à partir d'un fichier CSV spécifié pour les 48 Industries \n",
    "    du portefeuille.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str): Le chemin complet vers le fichier CSV contenant les données quotidiennes \n",
    "    des rendements des 48 Industries.\n",
    "\n",
    "    Return:\n",
    "    - pd.DataFrame: Un DataFrame contenant les données quotidiennes nettoyées et préparées \n",
    "        pour les 48 Industries du portefeuille, avec les dates en index.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Lecture du fichier CSV, avec l'en-tête à la ligne 6 (index 5)\n",
    "    df_daily = pd.read_csv(csv_file_path, header=5)\n",
    "\n",
    "    # Renommage de la première colonne pour indiquer qu'elle contient les dates\n",
    "    df_daily = df_daily.rename(columns={'Unnamed: 0': 'Date'})\n",
    "\n",
    "    # Copie et préparation des données jusqu'à la ligne spécifiée (25670)\n",
    "    df_daily_ret = df_daily.iloc[:25670].copy()\n",
    "    df_daily_ret['Date'] = pd.to_datetime(df_daily_ret['Date'], format='%Y%m%d')\n",
    "    df_daily_ret.set_index('Date', inplace=True)\n",
    "    df_daily_ret = df_daily_ret.apply(pd.to_numeric, errors='coerce')\n",
    "    df_daily_ret.replace(-99.99, np.nan, inplace=True)\n",
    "    df_daily_ret.replace(-999, np.nan, inplace=True)\n",
    "    df_daily_ret.dropna(inplace=True)\n",
    "\n",
    "    # Sélection d'un sous-ensemble des données à partir de la ligne spécifiée (232)\n",
    "    df_daily_ret = df_daily_ret.iloc[231:].copy()\n",
    "\n",
    "    return df_daily_ret\n",
    "\n",
    "\n",
    "def import_and_clean_FF_3factors_daily(csv_file_path, df_reference):\n",
    "    \"\"\"\n",
    "    Importe et nettoie les données des 3 quotidiennes des 3 facteurs Fama-French.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str): Chemin vers le fichier CSV contenant les données quotidiennes des facteurs Fama-French.\n",
    "    - df_reference (pd.DataFrame): DataFrame de référence pour aligner les indices de dates, (df_daily_ret) dans cet exemple.\n",
    "\n",
    "    Return:\n",
    "        pd.DataFrame: DataFrame contenant les données quotidiennes des 3 facteurs Fama-French nettoyées et alignées.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Lecture du fichier CSV, en supposant que l'en-tête se trouve à la 4ème ligne (index 3)\n",
    "    df_FF = pd.read_csv(csv_file_path, header=3)\n",
    "\n",
    "    # Renommage de la première colonne pour indiquer qu'elle contient les dates\n",
    "    df_FF = df_FF.rename(columns={'Unnamed: 0': 'Date'})\n",
    "\n",
    "    # Sélection des données jusqu'à la ligne spécifiée (25670 dans cet exemple)\n",
    "    df_FF_daily = df_FF.iloc[:25670].copy()\n",
    "\n",
    "    # Conversion de la colonne 'Date' au format datetime\n",
    "    df_FF_daily['Date'] = pd.to_datetime(df_FF_daily['Date'], format='%Y%m%d')\n",
    "\n",
    "    # Définition de la colonne 'Date' comme index du DataFrame\n",
    "    df_FF_daily.set_index('Date', inplace=True)\n",
    "\n",
    "    # Conversion des données en numérique, gestion des erreurs par coercition à NaN\n",
    "    df_FF_daily = df_FF_daily.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Remplacement des valeurs erronées ou manquantes spécifiques par NaN\n",
    "    df_FF_daily.replace(-99.99, np.nan, inplace=True)\n",
    "    df_FF_daily.replace(-999, np.nan, inplace=True)\n",
    "\n",
    "    # Suppression des lignes contenant des NaN pour assurer la complétude des données\n",
    "    df_FF_daily.dropna(inplace=True)\n",
    "\n",
    "    # Alignement du DataFrame des facteurs Fama-French avec l'index du DataFrame de référence\n",
    "    df_FF_daily_aligned = df_FF_daily.reindex(df_reference.index)\n",
    "\n",
    "    return df_FF_daily_aligned\n",
    "\n",
    "\n",
    "def import_FF_5factors_monthly(csv_file_path, df_reference):\n",
    "    \"\"\"\n",
    "    Importe et prépare les données des 5 facteurs de Fama-French à partir d'un fichier CSV contenant les facteurs mensuels.\n",
    "\n",
    "    Args:\n",
    "    - csv_file_path (str): Le chemin complet vers le fichier CSV contenant les données des 5 facteurs de Fama-French.\n",
    "    - df_reference (pd.DataFrame): DataFrame momemtum utilisé pour \"locker\" les données des 5 facteurs sur la base des dates de ce DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contenant les données des 5 facteurs de Fama-French nettoyées et préparées. \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Lecture du fichier CSV, l'en-tête se trouve à la 2ème ligne (index 1)\n",
    "    df_FF = pd.read_csv(csv_file_path, header=2)\n",
    "\n",
    "    # Renommage de la première colonne \n",
    "    df_FF = df_FF.rename(columns={'Unnamed: 0': 'Date'})\n",
    "\n",
    "    # Sélection des données pertinentes jusqu'à la ligne spécifiée (727)\n",
    "    df_FF = df_FF.iloc[:727].copy()\n",
    "\n",
    "    # Conversion de la colonne 'Date' en format datetime \n",
    "    df_FF['Date'] = pd.to_datetime(df_FF['Date'], format='%Y%m')\n",
    "\n",
    "    # Définition de la colonne 'Date' comme index du DataFrame \n",
    "    df_FF.set_index('Date', inplace=True)\n",
    "\n",
    "    # Conversion des valeurs du DataFrame en numérique, \n",
    "    # avec gestion des erreurs pour les valeurs non numériques\n",
    "    df_FF = df_FF.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Filtrage des données pour ne conserver que les dates présentes dans df_reference\n",
    "    df_FF = df_FF.loc[df_reference.index]\n",
    "\n",
    "    return df_FF\n",
    "\n",
    "\n",
    "\n",
    "def calculate_betas(start_date, end_date, df_daily_ret_reshaped, df_FF_daily):\n",
    "    # Sélectionner les données pour la plage de dates spécifiée\n",
    "    df_daily_ret_selected = df_daily_ret_reshaped.loc[start_date:end_date]\n",
    "    df_FF_daily_selected = df_FF_daily.loc[start_date:end_date]\n",
    "\n",
    "    # Maintenant, vous pouvez utiliser df_daily_ret_selected et df_FF_daily_selected pour votre régression\n",
    "    Rft = df_FF_daily_selected['RF']\n",
    "    Rm_t = df_FF_daily_selected['Mkt-RF']\n",
    "\n",
    "    betas = []  # Create an empty list to store the betas\n",
    "\n",
    "    for column in df_daily_ret_selected.columns:\n",
    "        Ri_t = df_daily_ret_selected[column]\n",
    "\n",
    "        Y = Ri_t - Rft\n",
    "        X = Rm_t\n",
    "\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "\n",
    "        betas.append(results.params[1])  # Add the betas to the list\n",
    "\n",
    "    # Convert the list of betas to a numpy array\n",
    "    betas = np.array(betas)\n",
    "\n",
    "    return betas\n",
    "\n",
    "\n",
    "def calculate_monthly_betas(df_daily_ret, df_FF_daily, df_48ind):\n",
    "    \"\"\"\n",
    "    Calcule les betas mensuels pour chaque mois à partir des données quotidiennes des rendements des 48 industries du portefeuille, \n",
    "    des facteurs Fama-French quotidiens et des 48 industries.\n",
    "\n",
    "    Args:\n",
    "    - df_daily_ret (pd.DataFrame): DataFrame contenant les rendements quotidiens.\n",
    "    - df_FF_daily (pd.DataFrame): DataFrame contenant les facteurs quotidiens de Fama-French.\n",
    "    - df_48ind (pd.DataFrame): DataFrame contenant des données pour les 48 industries, utilisé pour définir les indices et les noms des colonnes du résultat final.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame contenant les betas mensuels pour chaque mois, avec les dates comme index et les industries comme colonnes.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Obtenir la première et la dernière date dans les données\n",
    "    first_date = df_daily_ret.index.min()\n",
    "    last_date = df_daily_ret.index.max()\n",
    "\n",
    "    # Créer une plage de dates pour chaque mois dans les données\n",
    "    date_range = pd.date_range(start=first_date, end=last_date, freq='M')\n",
    "\n",
    "    # Calculer les betas pour chaque mois\n",
    "    monthly_betas = {}\n",
    "    for date in date_range:\n",
    "        start_date = date - pd.DateOffset(months=12)\n",
    "        end_date = date\n",
    "        betas = calculate_betas(start_date, end_date, df_daily_ret, df_FF_daily)  # Assurez-vous que la fonction `calculate_betas` est définie\n",
    "        monthly_betas[date] = betas\n",
    "\n",
    "    # Convertir le dictionnaire en DataFrame\n",
    "    df_monthly_betas = pd.DataFrame(monthly_betas.items(), columns=['Date', 'Betas'])\n",
    "\n",
    "    # Convertir la colonne 'Betas' de tableaux numpy en listes\n",
    "    df_monthly_betas['Betas'] = df_monthly_betas['Betas'].apply(list)\n",
    "\n",
    "    # Définir la colonne 'Date' comme index\n",
    "    df_monthly_betas.set_index('Date', inplace=True)\n",
    "\n",
    "    # Convertir chaque élément de la liste 'Betas' en une colonne distincte\n",
    "    df_monthly_betas = df_monthly_betas['Betas'].apply(pd.Series)\n",
    "\n",
    "    # Faire correspondre l'index de df_monthly_betas à df_48ind\n",
    "    df_monthly_betas.index = df_48ind.index\n",
    "\n",
    "    # Faire correspondre les noms des colonnes de df_monthly_betas à df_48ind\n",
    "    df_monthly_betas.columns = df_48ind.columns\n",
    "\n",
    "    return df_monthly_betas\n",
    "\n",
    "\n",
    "def calculate_idiosyncratic_volatility(start_date, end_date, df_daily_ret_reshaped, df_FF_daily):\n",
    "    # Sélectionner les données pour la plage de dates spécifiée\n",
    "    df_daily_ret_selected = df_daily_ret_reshaped.loc[start_date:end_date]\n",
    "    df_FF_daily_selected = df_FF_daily.loc[start_date:end_date]\n",
    "\n",
    "    # Maintenant, vous pouvez utiliser df_daily_ret_selected et df_FF_daily_selected pour votre régression\n",
    "    Rft = df_FF_daily_selected['RF']\n",
    "    Rm_t = df_FF_daily_selected['Mkt-RF']\n",
    "    SMB = df_FF_daily_selected['SMB']\n",
    "    HML = df_FF_daily_selected['HML']\n",
    "\n",
    "    volatilities = []  # Create an empty list to store the volatilities\n",
    "\n",
    "    for column in df_daily_ret_selected.columns:\n",
    "        Ri_t = df_daily_ret_selected[column]\n",
    "\n",
    "        Y = Ri_t - Rft\n",
    "        X = pd.concat([Rm_t, SMB, HML], axis=1)\n",
    "\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "\n",
    "        residuals = results.resid\n",
    "        volatility = np.std(residuals)\n",
    "\n",
    "        volatilities.append(volatility)  # Add the volatility to the list\n",
    "\n",
    "    # Convert the list of volatilities to a numpy array\n",
    "    volatilities = np.array(volatilities)\n",
    "\n",
    "    return volatilities\n",
    "\n",
    "\n",
    "def calculate_monthly_volatility(df_daily_ret, df_FF_daily_3factors_aligned, df_48Ind):\n",
    "    \"\"\"\n",
    "    Calcule les volatilités idiosyncratiques mensuelles pour chaque mois à partir des données quotidiennes des rendements, \n",
    "    des facteurs Fama-French quotidiens alignés et des 48 industries.\n",
    "\n",
    "    Args:\n",
    "    - df_daily_ret_reshaped (pd.DataFrame): DataFrame contenant les rendements quotidiens reshaped.\n",
    "    - df_daily_ret (pd.DataFrame): DataFrame contenant les rendements quotidiens.\n",
    "    - df_FF_daily_3factors_aligned (pd.DataFrame): DataFrame contenant les facteurs quotidiens de Fama-French alignés.\n",
    "    - df_48Ind (pd.DataFrame): DataFrame contenant des données pour les 48 industries.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame contenant les volatilités idiosyncratiques mensuelles pour chaque mois, \n",
    "                    avec les dates comme index et les industries comme colonnes.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Get the first and last date in the data\n",
    "    first_date = df_daily_ret.index.min()\n",
    "    last_date = df_daily_ret.index.max()\n",
    "\n",
    "    # Create a date range for each month in the data\n",
    "    date_range = pd.date_range(start=first_date, end=last_date, freq='M')\n",
    "\n",
    "    # Calculate the volatilities for each month\n",
    "    monthly_volatilities = {}\n",
    "    for date in date_range:\n",
    "        start_date = date - pd.DateOffset(months=1) + pd.DateOffset(days=1)\n",
    "        end_date = date\n",
    "        volatilities = calculate_idiosyncratic_volatility(start_date, end_date, df_daily_ret, df_FF_daily_3factors_aligned)\n",
    "        monthly_volatilities[date] = volatilities\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df_monthly_vol = pd.DataFrame(monthly_volatilities.items(), columns=['Date', 'Betas'])\n",
    "\n",
    "    # Convert the Betas column from numpy arrays to lists\n",
    "    df_monthly_vol['Betas'] = df_monthly_vol['Betas'].apply(list)\n",
    "\n",
    "    # Set the Date column as the index\n",
    "    df_monthly_vol.set_index('Date', inplace=True)\n",
    "\n",
    "    # Convert each item in the 'Betas' list to a separate column\n",
    "    df_monthly_vol = df_monthly_vol['Betas'].apply(pd.Series)\n",
    "\n",
    "    # Set the index of df_monthly_vol to match df_48Ind\n",
    "    df_monthly_vol.index = df_48Ind.index\n",
    "\n",
    "    # Set the column names of df_monthly_vol to match df_48Ind\n",
    "    df_monthly_vol.columns = df_48Ind.columns\n",
    "\n",
    "    return df_monthly_vol\n",
    "\n",
    "\n",
    "def select_extreme_values(row, num_values=5):\n",
    "    \"\"\"\n",
    "    Sélectionne les valeurs extrêmes dans une ligne (série) en fonction des valeurs triées dans l'ordre décroissant, \n",
    "    et retourne les premières valeurs les plus élevées et les dernières les plus basses, pour une caractéristique donnée.\n",
    "\n",
    "    Args:\n",
    "    - row (pd.Series): Une ligne (série) contenant les valeurs des caractéristiques à trier.\n",
    "    - num_values (int, optional): Le nombre d'industries avec la caractéristique extrêmes à sélectionner. Fixé à 5 par défaut.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Un tuple contenant deux pandas Series, les premières \"num_values\" valeurs les plus élevées \n",
    "            et les dernières \"num_values\" valeurs les plus basses pour chaque caractéristique donnée.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Triage dans l'ordre décroissant des caractéristiques (plus grande à plus petite) \n",
    "    sorted_row = row.sort_values(ascending=False)\n",
    "    \n",
    "    # Sélection des premières \"num_values\" valeurs les plus élevées\n",
    "    top_values = sorted_row.head(num_values)\n",
    "    \n",
    "    # Sélection des dernières \"num_values\" valeurs les plus basses\n",
    "    bottom_values = sorted_row.tail(num_values)\n",
    "    \n",
    "    return top_values, bottom_values\n",
    "\n",
    "\n",
    "def get_returns(caracteristic, df_ret_shift, num_positions, weight_type='ew'):\n",
    "    \"\"\"\n",
    "    Calcule les rendements totaux pour les positions longues et courtes basées sur les caractéristiques données, \n",
    "    les rendements des industries et le nombre de positions à prendre.\n",
    "\n",
    "    Args:\n",
    "    - caracteristic (pd.DataFrame): DataFrame contenant les caractéristiques de chaque industrie, \n",
    "                                    avec les dates en index et les industries en colonnes.\n",
    "    - df_ret_shift (pd.DataFrame): DataFrame contenant les rendements des industries, avec un décalage de t+1 (shifted by 1), \n",
    "                                    pour calculer les rendements totaux pour les positions longues et courtes.\n",
    "    - num_positions (int): Nombre de positions à prendre (par exemple, 5 industries extrêmes de chaque côté pour un total de 10 positions à chaque fois).\n",
    "    - weight_type (str, optional): Type de pondération à utiliser, 'ew' pour équipondéré ou 'vw' pour pondération par capitalisation boursière (marketcap).\n",
    "                                    Par défaut, 'ew', équipondéré.\n",
    "\n",
    "    Returns:\n",
    "    - list: Une liste contenant les rendements totaux pour les positions longues et courtes à la fin de chaque mois t+1. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Sélectionne les valeurs extrêmes pour chaque mois t \n",
    "    top_bottom_values = caracteristic.apply(select_extreme_values, axis=1)\n",
    "    \n",
    "    returns = []  # Initialise une liste pour stocker les rendements individuels pour chaque mois\n",
    "    total_returns = []  # Initialise une liste pour stocker les rendements totaux pour chaque mois\n",
    "    \n",
    "    # Itération à travers toutes les valeurs extrêmes pour chaque mois \n",
    "    for date, values in top_bottom_values.items():\n",
    "        top_indices, bottom_indices = values[0].index, values[1].index\n",
    "        \n",
    "        # Calcul des rendements pour les positions longues et courtes en fonction du type de pondération spécifié \n",
    "        if weight_type == 'ew':\n",
    "            weight = 1.0 / num_positions  # Poids égal pour chaque position\n",
    "            top_returns = df_ret_shift.loc[date, top_indices] * weight\n",
    "            bottom_returns = df_ret_shift.loc[date, bottom_indices] * weight * -1  # Les positions courtes ont un poids négatif\n",
    "        elif weight_type == 'vw':\n",
    "            top_values = df_ret_shift.loc[date, top_indices]\n",
    "            bottom_values = df_ret_shift.loc[date, bottom_indices]\n",
    "            top_weights = top_values.abs() / top_values.abs().sum()  # Pondération par capitalisation boursière absolue \n",
    "            bottom_weights = bottom_values.abs() / bottom_values.abs().sum()  # Pondération par capitalisation boursière absolue \n",
    "            top_returns = top_values * top_weights \n",
    "            bottom_returns = bottom_values * bottom_weights * -1  # Les positions courtes ont un poids négatif \n",
    "        else:\n",
    "            raise ValueError(\"weight_type must be either 'ew' or 'vw'\")\n",
    "        \n",
    "        # Ajoute les rendements longs et courts à la liste des rendements\n",
    "        returns.append((top_returns.sum(), bottom_returns.sum()))  \n",
    "    \n",
    "    # Calcule les rendements totaux pour chaque mois\n",
    "    total_returns = [sum(x) for x in returns]  \n",
    "\n",
    "    return total_returns\n",
    "\n",
    "\n",
    "def get_sharpe_and_constants(caracteristic, df_ret_shift, num_positions, df_FF_daily_3factors_aligned, df_FF_5, weight_type='ew'):\n",
    "    \"\"\"\n",
    "    Calcule le ratio de Sharpe et les constantes de régression (Alpha de Jensen) pour les rendements totaux des stratégies 'EW' et 'VW' en fonction des caractéristiques données,\n",
    "    des rendements journaliers des 48 industries, du nombre de positions longues et courtes à prendre, du taux sans risque moyen annualisé selon la formule du (CAGR) et des 3, 4 et 5 facteurs de Fama-French.\n",
    "\n",
    "    Args:\n",
    "    - caracteristic (pd.DataFrame): DataFrame contenant les caractéristiques de chaque industrie, \n",
    "                                    avec les dates en index et les industries en colonnes.\n",
    "    - df_ret_shift (pd.DataFrame): DataFrame contenant les rendements des industries, avec un décalage de t+1, \n",
    "                                    pour calculer les rendements totaux pour les positions longues et courtes.\n",
    "    - num_positions (int): Nombre de positions à prendre (par exemple, 5 industries extrêmes de chaque côté pour un total de 10 positions à chaque fois).\n",
    "    - rf (float): Taux sans risque mensuel moyen sur la période.\n",
    "    - df_FF_5 (pd.DataFrame): DataFrame contenant les 5 facteurs de Fama-French, \n",
    "                                utilisés dans la régression pour calculer les constantes.\n",
    "    - weight_type (str, optional): Type de pondération à utiliser, 'ew' pour équipondéré ou 'vw' pour pondération par capitalisation boursière.\n",
    "                                    Par défaut, 'ew', équipondéré.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Un tuple contenant le ratio de Sharpe et les constantes de régression pour 3, 4 et 5 facteurs.\n",
    "    \"\"\"\n",
    "    # Calculer le rendement annualisé du taux sans risque, selon la formule du taux de rendement annuel composé (CAGR)\n",
    "    mean_rf_monthly = df_FF_daily_3factors_aligned['RF'].mean()\n",
    "    mean_rf_annual = ((1 + mean_rf_monthly/100) ** 12 - 1)\n",
    "    mean_rf_annual*=100\n",
    "\n",
    "    # Obtenir les rendements totaux pour les positions longues et courtes \n",
    "    # en fonction du triage des caractéristiques et du type de pondération\n",
    "    total_returns = get_returns(caracteristic, df_ret_shift, num_positions, weight_type)\n",
    "\n",
    "    # Convertir la liste en pandas Series \n",
    "    total_returns_series = pd.Series(total_returns)\n",
    "    \n",
    "    # Calculer la moyenne et l'écart-type des rendements mensuels du portefeuille pour la période indiquée\n",
    "    mean_return_monthly = total_returns_series.mean()\n",
    "    std_return_monthly = total_returns_series.std()\n",
    "\n",
    "    # Annualiser la moyenne et l'écart-type des rendements mensuels, avec la formule du taux de rendement annuel composé (CAGR)\n",
    "    mean_return_annualized = (1 + mean_return_monthly/100) ** 12 - 1 \n",
    "    std_return_annualized = std_return_monthly * np.sqrt(12) \n",
    "\n",
    "    # Convertir en pourcentage pour faciliter les manipulations par la suite\n",
    "    mean_return_annualized = mean_return_annualized * 100 \n",
    "\n",
    "    # Calculer le ratio de Sharpe pour les rendements totaux \n",
    "    sharpe_ratio = (mean_return_annualized - mean_rf_annual) / std_return_annualized\n",
    "\n",
    "    # Convertir la liste en pandas DataFrame pour la régression pour obtenir les alpha de Jensen \n",
    "    total_returns_df = pd.DataFrame(total_returns, columns=['returns'])\n",
    "\n",
    "    # Réinitialiser l'index pour les deux DataFrames \n",
    "    total_returns_df = total_returns_df.reset_index(drop=True)\n",
    "    df_FF_5 = df_FF_5.reset_index(drop=True)\n",
    "\n",
    "    # Régression avec 3, 4 et 5 facteurs de Fama-French pour obtenir les constantes (Alpha de Jensen)\n",
    "    constants = []\n",
    "    for num_factors in [3, 4, 5]:\n",
    "        factors = sm.add_constant(df_FF_5.iloc[:, :num_factors])\n",
    "        model = sm.OLS(total_returns_df, factors)\n",
    "        results = model.fit()\n",
    "        constants.append(results.params['const'])\n",
    "\n",
    "    # Retourner le ratio de Sharpe et les constantes de régression pour 3, 4 et 5 facteurs \n",
    "    return sharpe_ratio, constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP2 Notebook Partie B.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorer les avertissements de type FutureWarning et DtypeWarning pour une meilleure lisibilité des résultats\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "\n",
    "# Import data and clean\n",
    "csv_file_path_10ind         = '/Users/thomasdeconinck/Downloads/Gestion-de-Portefeuille-Devoir-2/Partie A/Data /48_Industry_Portfolios.CSV'\n",
    "df_48Ind                    = importClean_Ind(csv_file_path_10ind, desired_returns='Average Value Weighted Returns -- Monthly')\n",
    "\n",
    "csv_file_path_number_firm   = '/Users/thomasdeconinck/Downloads/Gestion-de-Portefeuille-Devoir-2/Partie A/Data /48_Industry_Portfolios.CSV'\n",
    "df_number_firm              = importClean_Ind(csv_file_path_number_firm, desired_returns='Number of Firms in Portfolios')\n",
    "df_number_firm              = df_number_firm[df_number_firm.index >= df_48Ind.index.min()]\n",
    "\n",
    "csv_file_path_avg_firm_size = '/Users/thomasdeconinck/Downloads/Gestion-de-Portefeuille-Devoir-2/Partie A/Data /48_Industry_Portfolios.CSV'\n",
    "df_average_firm_size        = importClean_Ind(csv_file_path_avg_firm_size, desired_returns='Average Firm Size')\n",
    "\n",
    "csv_file_path_rf            = '/Users/thomasdeconinck/Documents/GitHub/Gestion de Portefeuille Devoir 2/Partie A/Data /F-F_Research_Data_Factors.CSV'\n",
    "df_rf                       = importClean_rf(csv_file_path_rf)\n",
    "\n",
    "\n",
    "csv_file_path_daily_ret = '/Users/thomasdeconinck/Downloads/Gestion-de-Portefeuille-Devoir-2/Partie B/Data/48_Industry_Portfolios_Daily.csv' \n",
    "desired_returns = \"Average Value Weighted Returns -- Daily\"\n",
    "\n",
    "df_48Ind_daily = import_and_prepare_daily_data(csv_file_path_daily_ret)\n",
    "\n",
    "\n",
    "csv_file_path_FF_daily_factors = '/Users/thomasdeconinck/Downloads/Gestion-de-Portefeuille-Devoir-2/Partie B/Data/F-F_Research_Data_Factors_daily.CSV'\n",
    "df_FF_daily_3factors_aligned = import_and_clean_FF_3factors_daily(csv_file_path_FF_daily_factors, df_48Ind_daily)\n",
    "\n",
    "\n",
    "csv_file_path = '/Users/thomasdeconinck/Downloads/Gestion-de-Portefeuille-Devoir-2/Partie B/Data/F-F_Research_Data_5_Factors_2x3-2.csv'\n",
    "df_FF_5 = import_FF_5factors_monthly(csv_file_path, df_mom)\n",
    "\n",
    "\n",
    "# 2 Fama-French factors and Momentum factor data and calculation\n",
    "# 1) SMB (Small Minus Big) : Market capitalization\n",
    "market_caps                 = df_average_firm_size.multiply(df_number_firm)\n",
    "\n",
    "# 2) HML (High Minus Low) : Book to Market ratio\n",
    "csv_file_path_BtoM          = '/Users/thomasdeconinck/Downloads/Gestion-de-Portefeuille-Devoir-2/Partie A/Data /48_Industry_Portfolios.CSV'\n",
    "df_BtoM                     = importClean_Ind(csv_file_path_BtoM, desired_returns='Sum of BE / Sum of ME')\n",
    "df_BtoM                     = df_BtoM.loc[df_BtoM.index.repeat(12)]\n",
    "df_BtoM                     = df_BtoM.iloc[:len(df_48Ind)]\n",
    "df_BtoM.index               = df_48Ind.index\n",
    "\n",
    "# 3) UMD (Up Minus Down) : momentum (average of 12 months)\n",
    "df_mom                      = df_48Ind.rolling(window=12, min_periods=12).mean()\n",
    "df_mom.replace(-99.99, np.nan, inplace = True)\n",
    "df_mom.replace(-999, np.nan, inplace = True)\n",
    "df_mom.dropna(inplace = True)\n",
    "\n",
    "\n",
    "# S'assurer que les données sont sur la même période de temps \n",
    "df_BtoM                    = df_BtoM.reindex(df_mom.index)\n",
    "market_caps                = market_caps.reindex(df_mom.index)\n",
    "df_48Ind                   = df_48Ind.reindex(df_mom.index)\n",
    "\n",
    "\n",
    "# Rp,t+1 : Rendements des 48 industries à t+1 \n",
    "df_ret_shift               = df_48Ind.shift(-1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>EW Sharpe Ratio</th>\n",
       "      <th>EW Jensen Alpha</th>\n",
       "      <th>VW Sharpe Ratio</th>\n",
       "      <th>VW Jensen Alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Range</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-06-01 to 2024-01-01</th>\n",
       "      <td>Market Cap</td>\n",
       "      <td>-0.127897</td>\n",
       "      <td>[0.1745, 0.3631, 0.4169]</td>\n",
       "      <td>-0.255976</td>\n",
       "      <td>[-0.1623, 0.0926, 0.1823]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-01 to 2024-01-01</th>\n",
       "      <td>Market Cap</td>\n",
       "      <td>-0.083278</td>\n",
       "      <td>[0.085, 0.3132, 0.3783]</td>\n",
       "      <td>-0.211512</td>\n",
       "      <td>[-0.3105, 0.0306, 0.152]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 to 2024-01-01</th>\n",
       "      <td>Market Cap</td>\n",
       "      <td>-0.314124</td>\n",
       "      <td>[-0.2021, 0.0496, 0.1334]</td>\n",
       "      <td>-0.352049</td>\n",
       "      <td>[-0.6129, -0.1922, -0.028]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-06-01 to 2024-01-01</th>\n",
       "      <td>Book-to_Market</td>\n",
       "      <td>0.183995</td>\n",
       "      <td>[-0.1493, -0.1108, -0.0864]</td>\n",
       "      <td>0.153947</td>\n",
       "      <td>[-0.1707, -0.1836, -0.2267]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-01 to 2024-01-01</th>\n",
       "      <td>Book-to_Market</td>\n",
       "      <td>0.096451</td>\n",
       "      <td>[-0.1514, -0.1459, -0.1355]</td>\n",
       "      <td>0.110105</td>\n",
       "      <td>[-0.0631, -0.1078, -0.1726]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 to 2024-01-01</th>\n",
       "      <td>Book-to_Market</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>[0.008, -0.0162, -0.0384]</td>\n",
       "      <td>0.199230</td>\n",
       "      <td>[0.0888, 0.0234, -0.1289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-06-01 to 2024-01-01</th>\n",
       "      <td>Momentum</td>\n",
       "      <td>3.513027</td>\n",
       "      <td>[4.7936, 4.7922, 4.621]</td>\n",
       "      <td>3.566692</td>\n",
       "      <td>[6.3534, 6.336, 6.1196]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-01 to 2024-01-01</th>\n",
       "      <td>Momentum</td>\n",
       "      <td>3.628877</td>\n",
       "      <td>[5.1244, 5.1124, 4.9382]</td>\n",
       "      <td>3.585076</td>\n",
       "      <td>[6.7546, 6.7281, 6.4828]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 to 2024-01-01</th>\n",
       "      <td>Momentum</td>\n",
       "      <td>3.345677</td>\n",
       "      <td>[5.0628, 4.9431, 4.706]</td>\n",
       "      <td>3.430313</td>\n",
       "      <td>[6.7757, 6.5435, 6.2124]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-06-01 to 2024-01-01</th>\n",
       "      <td>Monthly Betas</td>\n",
       "      <td>0.034669</td>\n",
       "      <td>[-0.3292, -0.1863, 0.0601]</td>\n",
       "      <td>-0.027796</td>\n",
       "      <td>[-0.4898, -0.2773, 0.0356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-01 to 2024-01-01</th>\n",
       "      <td>Monthly Betas</td>\n",
       "      <td>0.121681</td>\n",
       "      <td>[-0.3698, -0.1251, 0.1689]</td>\n",
       "      <td>0.076106</td>\n",
       "      <td>[-0.4526, -0.0919, 0.2917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 to 2024-01-01</th>\n",
       "      <td>Monthly Betas</td>\n",
       "      <td>-0.153182</td>\n",
       "      <td>[-0.9588, -0.6811, -0.3566]</td>\n",
       "      <td>-0.130317</td>\n",
       "      <td>[-1.1029, -0.703, -0.2742]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-06-01 to 2024-01-01</th>\n",
       "      <td>Monthly vol. idiosyncratic</td>\n",
       "      <td>-0.085947</td>\n",
       "      <td>[-0.2456, -0.2916, -0.3172]</td>\n",
       "      <td>0.174692</td>\n",
       "      <td>[0.1116, 0.0679, 0.0577]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-01 to 2024-01-01</th>\n",
       "      <td>Monthly vol. idiosyncratic</td>\n",
       "      <td>-0.270554</td>\n",
       "      <td>[-0.5399, -0.5867, -0.62]</td>\n",
       "      <td>0.031411</td>\n",
       "      <td>[-0.242, -0.3037, -0.314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 to 2024-01-01</th>\n",
       "      <td>Monthly vol. idiosyncratic</td>\n",
       "      <td>-0.145831</td>\n",
       "      <td>[-0.4251, -0.5775, -0.5666]</td>\n",
       "      <td>0.108663</td>\n",
       "      <td>[-0.0666, -0.3133, -0.2737]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           DataFrame  EW Sharpe Ratio  \\\n",
       "Date Range                                                              \n",
       "1970-06-01 to 2024-01-01                  Market Cap        -0.127897   \n",
       "1990-01-01 to 2024-01-01                  Market Cap        -0.083278   \n",
       "2000-01-01 to 2024-01-01                  Market Cap        -0.314124   \n",
       "1970-06-01 to 2024-01-01              Book-to_Market         0.183995   \n",
       "1990-01-01 to 2024-01-01              Book-to_Market         0.096451   \n",
       "2000-01-01 to 2024-01-01              Book-to_Market         0.249354   \n",
       "1970-06-01 to 2024-01-01                    Momentum         3.513027   \n",
       "1990-01-01 to 2024-01-01                    Momentum         3.628877   \n",
       "2000-01-01 to 2024-01-01                    Momentum         3.345677   \n",
       "1970-06-01 to 2024-01-01               Monthly Betas         0.034669   \n",
       "1990-01-01 to 2024-01-01               Monthly Betas         0.121681   \n",
       "2000-01-01 to 2024-01-01               Monthly Betas        -0.153182   \n",
       "1970-06-01 to 2024-01-01  Monthly vol. idiosyncratic        -0.085947   \n",
       "1990-01-01 to 2024-01-01  Monthly vol. idiosyncratic        -0.270554   \n",
       "2000-01-01 to 2024-01-01  Monthly vol. idiosyncratic        -0.145831   \n",
       "\n",
       "                                      EW Jensen Alpha  VW Sharpe Ratio  \\\n",
       "Date Range                                                               \n",
       "1970-06-01 to 2024-01-01     [0.1745, 0.3631, 0.4169]        -0.255976   \n",
       "1990-01-01 to 2024-01-01      [0.085, 0.3132, 0.3783]        -0.211512   \n",
       "2000-01-01 to 2024-01-01    [-0.2021, 0.0496, 0.1334]        -0.352049   \n",
       "1970-06-01 to 2024-01-01  [-0.1493, -0.1108, -0.0864]         0.153947   \n",
       "1990-01-01 to 2024-01-01  [-0.1514, -0.1459, -0.1355]         0.110105   \n",
       "2000-01-01 to 2024-01-01    [0.008, -0.0162, -0.0384]         0.199230   \n",
       "1970-06-01 to 2024-01-01      [4.7936, 4.7922, 4.621]         3.566692   \n",
       "1990-01-01 to 2024-01-01     [5.1244, 5.1124, 4.9382]         3.585076   \n",
       "2000-01-01 to 2024-01-01      [5.0628, 4.9431, 4.706]         3.430313   \n",
       "1970-06-01 to 2024-01-01   [-0.3292, -0.1863, 0.0601]        -0.027796   \n",
       "1990-01-01 to 2024-01-01   [-0.3698, -0.1251, 0.1689]         0.076106   \n",
       "2000-01-01 to 2024-01-01  [-0.9588, -0.6811, -0.3566]        -0.130317   \n",
       "1970-06-01 to 2024-01-01  [-0.2456, -0.2916, -0.3172]         0.174692   \n",
       "1990-01-01 to 2024-01-01    [-0.5399, -0.5867, -0.62]         0.031411   \n",
       "2000-01-01 to 2024-01-01  [-0.4251, -0.5775, -0.5666]         0.108663   \n",
       "\n",
       "                                      VW Jensen Alpha  \n",
       "Date Range                                             \n",
       "1970-06-01 to 2024-01-01    [-0.1623, 0.0926, 0.1823]  \n",
       "1990-01-01 to 2024-01-01     [-0.3105, 0.0306, 0.152]  \n",
       "2000-01-01 to 2024-01-01   [-0.6129, -0.1922, -0.028]  \n",
       "1970-06-01 to 2024-01-01  [-0.1707, -0.1836, -0.2267]  \n",
       "1990-01-01 to 2024-01-01  [-0.0631, -0.1078, -0.1726]  \n",
       "2000-01-01 to 2024-01-01    [0.0888, 0.0234, -0.1289]  \n",
       "1970-06-01 to 2024-01-01      [6.3534, 6.336, 6.1196]  \n",
       "1990-01-01 to 2024-01-01     [6.7546, 6.7281, 6.4828]  \n",
       "2000-01-01 to 2024-01-01     [6.7757, 6.5435, 6.2124]  \n",
       "1970-06-01 to 2024-01-01   [-0.4898, -0.2773, 0.0356]  \n",
       "1990-01-01 to 2024-01-01   [-0.4526, -0.0919, 0.2917]  \n",
       "2000-01-01 to 2024-01-01   [-1.1029, -0.703, -0.2742]  \n",
       "1970-06-01 to 2024-01-01     [0.1116, 0.0679, 0.0577]  \n",
       "1990-01-01 to 2024-01-01    [-0.242, -0.3037, -0.314]  \n",
       "2000-01-01 to 2024-01-01  [-0.0666, -0.3133, -0.2737]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cacluler les betas mensuels avec la fonction calculate_monthly_betas \n",
    "df_monthly_betas = calculate_monthly_betas(df_48Ind_daily, df_FF_daily_3factors_aligned, df_48Ind)\n",
    "\n",
    "# Calculer les volatilités idiosyncratiques mensuelles avec la fonction calculate_monthly_volatility\n",
    "df_monthly_vol = calculate_monthly_volatility(df_48Ind_daily, df_FF_daily_3factors_aligned, df_48Ind)\n",
    "\n",
    "dataframes = [market_caps, df_BtoM, df_mom, df_monthly_betas, df_monthly_vol]\n",
    "names = ['Market Cap', 'Book-to_Market', 'Momentum', 'Monthly Betas', 'Monthly vol. idiosyncratic']\n",
    "date_ranges = [('1970-06-01', '2024-01-01'), ('1990-01-01', '2024-01-01'), ('2000-01-01', '2024-01-01')]\n",
    "\n",
    "# Créez un DataFrame vide pour stocker les résultats finaux pour chaque combinaison de DataFrame et de plage de dates \n",
    "results_df = pd.DataFrame(columns=['DataFrame', 'Date Range', 'EW Sharpe Ratio', 'EW Jensen Alpha', 'VW Sharpe Ratio', 'VW Jensen Alpha'])\n",
    "\n",
    "# Itérez sur les DataFrames et les plages de dates pour calculer les ratios de Sharpe et les alpha de Jensen  \n",
    "for df, name in zip(dataframes, names):\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filtrer le DataFrame pour la plage de dates donnée pour chaque itération\n",
    "        df_filtered = df.loc[start_date:end_date]\n",
    "        df_FF_5_filtered = df_FF_5.loc[start_date:end_date]\n",
    "\n",
    "        # Calculer le ratio de Sharpe et les alpha de Jensen pour les pondérations EW et VW (les 2 stratégies évaluées)\n",
    "        sharpe_ratio_ew, constants_ew = get_sharpe_and_constants(df_filtered, df_48Ind, 5, df_FF_daily_3factors_aligned, df_FF_5_filtered, 'ew')\n",
    "        sharpe_ratio_vw, constants_vw = get_sharpe_and_constants(df_filtered, df_48Ind, 5, df_FF_daily_3factors_aligned, df_FF_5_filtered, 'vw')\n",
    "\n",
    "        # Arrondir les constantes à 4 décimales pour une meilleure lisibilité\n",
    "        constants_ew_rounded = [round(constant, 4) for constant in constants_ew]\n",
    "        constants_vw_rounded = [round(constant, 4) for constant in constants_vw]\n",
    "\n",
    "        # Convertir les constantes en chaînes de caractères pour stockage dans le DataFrame\n",
    "        constants_ew_str = [str(constant) for constant in constants_ew_rounded]\n",
    "        constants_vw_str = [str(constant) for constant in constants_vw_rounded]\n",
    "\n",
    "        # Ajouter les résultats au DataFrame final \n",
    "        results_df = pd.concat([results_df, pd.DataFrame({'DataFrame': [name],\n",
    "                                                        'Date Range': [f\"{start_date} to {end_date}\"],\n",
    "                                                        'EW Sharpe Ratio': [sharpe_ratio_ew],\n",
    "                                                        'EW Jensen Alpha': [constants_ew_str],\n",
    "                                                        'VW Sharpe Ratio': [sharpe_ratio_vw],\n",
    "                                                        'VW Jensen Alpha': [constants_vw_str]})], ignore_index=True)\n",
    "\n",
    "# Définir les dates comme index du DataFrame final\n",
    "results_df.set_index('Date Range', inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/dominicprenovost/Programmation/TP2-PF-management/48_Industry_Portfolios.CSV'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_monthly \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/dominicprenovost/Programmation/TP2-PF-management/48_Industry_Portfolios.CSV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_monthly \u001b[38;5;241m=\u001b[39m df_monthly\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      4\u001b[0m df_48ind \u001b[38;5;241m=\u001b[39m df_monthly\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m1171\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dominicprenovost/Programmation/TP2-PF-management/48_Industry_Portfolios.CSV'"
     ]
    }
   ],
   "source": [
    "\n",
    "########## boucle pour toutes les colonnes, avec une date de début et de fin pour chaque mois:\n",
    "\n",
    "def get_sharpe_and_constants(caracteristic, df_ret_shift, num_positions, rf, df_FF_5, weight_type='ew'):\n",
    "    total_returns = get_returns(caracteristic, df_ret_shift, num_positions, weight_type)\n",
    "\n",
    "    # Convert list to pandas Series\n",
    "    total_returns_series = pd.Series(total_returns)\n",
    "\n",
    "    # Calculate Sharpe ratio\n",
    "    sharpe_ratio = ((total_returns_series.mean() - rf) / total_returns_series.std()) * np.sqrt(12)\n",
    "\n",
    "    # Convert list to pandas DataFrame\n",
    "    total_returns_df = pd.DataFrame(total_returns, columns=['returns'])\n",
    "\n",
    "    # Reset index\n",
    "    total_returns_df = total_returns_df.reset_index(drop=True)\n",
    "    df_FF_5 = df_FF_5.reset_index(drop=True)\n",
    "\n",
    "    # Regression with 3, 4, and 5 factors\n",
    "    constants = []\n",
    "    for num_factors in [3, 4, 5]:\n",
    "        factors = sm.add_constant(df_FF_5.iloc[:, :num_factors])\n",
    "        model = sm.OLS(total_returns_df, factors)\n",
    "        results = model.fit()\n",
    "        constants.append(results.params['const'])\n",
    "\n",
    "    return sharpe_ratio, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For df_MC from 1970-06-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.12903594319668069\n",
      "EW Constants:  [0.1744608932148895, 0.36313018564047694, 0.41686805413367434]\n",
      "VW Sharpe Ratio:  -0.2638945743872925\n",
      "VW Constants:  [-0.1623462740384269, 0.09261705895242703, 0.1823155088663715]\n",
      "\n",
      "\n",
      "For df_MC from 1990-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.08380310703698962\n",
      "EW Constants:  [0.08498345574364308, 0.31321890666469904, 0.37834052903149046]\n",
      "VW Sharpe Ratio:  -0.21754452007960087\n",
      "VW Constants:  [-0.3105169510924926, 0.030599113423459178, 0.15201290942600637]\n",
      "\n",
      "\n",
      "For df_MC from 2000-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.32265847026153704\n",
      "EW Constants:  [-0.20212459364281926, 0.04962713675650925, 0.13339816783416092]\n",
      "VW Sharpe Ratio:  -0.370356563473417\n",
      "VW Constants:  [-0.6129138022701306, -0.19224205940097078, -0.028036689082665513]\n",
      "\n",
      "\n",
      "For df_BtoM from 1970-06-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.31282307408555426\n",
      "EW Constants:  [-0.8677918194689576, -0.8073048677898551, -0.725928504649743]\n",
      "VW Sharpe Ratio:  -0.3354894051985584\n",
      "VW Constants:  [-1.269858827748963, -1.2239013569492876, -1.1549806639428277]\n",
      "\n",
      "\n",
      "For df_BtoM from 1990-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.3801817459041151\n",
      "EW Constants:  [-0.9078181467264198, -0.8864429387407059, -0.8181080034186291]\n",
      "VW Sharpe Ratio:  -0.3587206142379057\n",
      "VW Constants:  [-1.2508922936919282, -1.229151489252005, -1.1698926131536571]\n",
      "\n",
      "\n",
      "For df_BtoM from 2000-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.2597333328247108\n",
      "EW Constants:  [-0.8429023936178159, -0.808398993434738, -0.7523482038335872]\n",
      "VW Sharpe Ratio:  -0.289352899015965\n",
      "VW Constants:  [-1.2190675975894558, -1.0965420747094357, -1.0859690535293087]\n",
      "\n",
      "\n",
      "For df_mom from 1970-06-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  2.7118280860349877\n",
      "EW Constants:  [4.793559449846718, 4.792219411986009, 4.620989552863255]\n",
      "VW Sharpe Ratio:  2.519923920228778\n",
      "VW Constants:  [6.35343030732958, 6.335981563275756, 6.119596378254618]\n",
      "\n",
      "\n",
      "For df_mom from 1990-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  2.7540007904821935\n",
      "EW Constants:  [5.12437951679825, 5.11237139091732, 4.938209675693555]\n",
      "VW Sharpe Ratio:  2.4758592867316014\n",
      "VW Constants:  [6.754612903748293, 6.728060731236724, 6.482844623049739]\n",
      "\n",
      "\n",
      "For df_mom from 2000-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  2.5488799565617946\n",
      "EW Constants:  [5.06279495289191, 4.943108524435301, 4.7059599965762935]\n",
      "VW Sharpe Ratio:  2.3665989383080133\n",
      "VW Constants:  [6.775707072219265, 6.543545523321069, 6.212355048863954]\n",
      "\n",
      "\n",
      "For df_monthly_betas from 1970-06-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  0.03927035704873203\n",
      "EW Constants:  [-0.3182958859746001, -0.17736931033460399, 0.07062671140415183]\n",
      "VW Sharpe Ratio:  -0.02575002560604163\n",
      "VW Constants:  [-0.48345126973849406, -0.27226084854084037, 0.041156112761394276]\n",
      "\n",
      "\n",
      "For df_monthly_betas from 1990-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  0.11970250353982466\n",
      "EW Constants:  [-0.36975422035817324, -0.12512706026463302, 0.1688748373546719]\n",
      "VW Sharpe Ratio:  0.07497411345807638\n",
      "VW Constants:  [-0.4526407832410668, -0.09191450551229842, 0.2917192178724447]\n",
      "\n",
      "\n",
      "For df_monthly_betas from 2000-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.15591739592191592\n",
      "EW Constants:  [-0.9588063392773357, -0.6810846607755783, -0.35663313660468665]\n",
      "VW Sharpe Ratio:  -0.13307175351372966\n",
      "VW Constants:  [-1.1028888526605232, -0.7030089160986472, -0.2742410136581264]\n",
      "\n",
      "\n",
      "For df_monthly_vol from 1970-06-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.08649301321803261\n",
      "EW Constants:  [-0.24560539107222826, -0.29157903311247685, -0.3172450620169757]\n",
      "VW Sharpe Ratio:  0.1703395639102814\n",
      "VW Constants:  [0.11161522134682138, 0.06785206098248509, 0.057712922167305614]\n",
      "\n",
      "\n",
      "For df_monthly_vol from 1990-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.2766186840191347\n",
      "EW Constants:  [-0.5398603087087692, -0.586719868390357, -0.6200395451933511]\n",
      "VW Sharpe Ratio:  0.031144950061611082\n",
      "VW Constants:  [-0.2419668871257304, -0.3037014229256835, -0.31396930842825016]\n",
      "\n",
      "\n",
      "For df_monthly_vol from 2000-01-01 to 2024-01-01:\n",
      "EW Sharpe Ratio:  -0.14767320861019134\n",
      "EW Constants:  [-0.4250837988490552, -0.5774989391686903, -0.5665582001745377]\n",
      "VW Sharpe Ratio:  0.10658963136452408\n",
      "VW Constants:  [-0.06663670087821191, -0.3132757217360278, -0.2737291748307122]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes = [df_MC, df_BtoM, df_mom, df_monthly_betas, df_monthly_vol]\n",
    "names = ['df_MC', 'df_BtoM', 'df_mom', 'df_monthly_betas', 'df_monthly_vol']\n",
    "date_ranges = [('1970-06-01', '2024-01-01'), ('1990-01-01', '2024-01-01'), ('2000-01-01', '2024-01-01')]\n",
    "\n",
    "for df, name in zip(dataframes, names):\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the DataFrame for the given date range\n",
    "        df_filtered = df.loc[start_date:end_date]\n",
    "        df_FF_5_filtered = df_FF_5.loc[start_date:end_date]\n",
    "\n",
    "        # Calculate Sharpe ratio and constants\n",
    "        sharpe_ratio_ew, constants_ew = get_sharpe_and_constants(df_filtered, df_48ind, 5, rf, df_FF_5_filtered, 'ew')\n",
    "        sharpe_ratio_vw, constants_vw = get_sharpe_and_constants(df_filtered, df_48ind, 5, rf, df_FF_5_filtered, 'vw')\n",
    "\n",
    "        # Print results\n",
    "        print(f\"For {name} from {start_date} to {end_date}:\")\n",
    "        print(\"EW Sharpe Ratio: \", sharpe_ratio_ew)\n",
    "        print(\"EW Constants: \", constants_ew)\n",
    "        print(\"VW Sharpe Ratio: \", sharpe_ratio_vw)\n",
    "        print(\"VW Constants: \", constants_vw)\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HECFinance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
